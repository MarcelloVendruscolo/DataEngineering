{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "instructional-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#New API\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.113:7077\") \\\n",
    "        .appName(\"marcelloVendruscolo_A1\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.driver.port\",9998)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "#Old API (RDD)\n",
    "spark_context = spark_session.sparkContext\n",
    "spark_context.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interested-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to (i) lowercase and (ii) tokenize (split on space) text\n",
    "def func_lowercase_split(rdd):\n",
    "    return rdd.lower().split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unlimited-recovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: europarl-v7.sv-en.en\n",
      "Line counting: 1862234\n",
      "Partition counting: 2\n"
     ]
    }
   ],
   "source": [
    "#A.1.1 and A.1.4 - Read the English transcripts with Spark, and count the number of lines and partitions.\n",
    "print(\"File: europarl-v7.sv-en.en\")\n",
    "en_1 = spark_context.textFile(\"hdfs://192.168.2.113:9000/europarl/europarl-v7.sv-en.en\")\n",
    "lineCount_en_1 = en_1.count()\n",
    "print(\"Line counting: \" + str(lineCount_en_1))\n",
    "print(\"Partition counting: \" + str(en_1.getNumPartitions()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "indirect-enough",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: europarl-v7.sv-en.sv\n",
      "Line counting: 1862234\n",
      "Partition counting: 3\n"
     ]
    }
   ],
   "source": [
    "#A.1.2 and A.1.4 - Read the Swedish transcripts with Spark, and count the number of lines and partitions.\n",
    "print(\"File: europarl-v7.sv-en.sv\")\n",
    "sv_1 = spark_context.textFile(\"hdfs://192.168.2.113:9000/europarl/europarl-v7.sv-en.sv\")\n",
    "lineCount_sv_1 = sv_1.count()\n",
    "print(\"Line counting: \" + str(lineCount_sv_1))\n",
    "print(\"Partition counting: \" + str(sv_1.getNumPartitions()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "entertaining-isaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line counts are the same for both europarl-v7.sv-en.en and europarl-v7.sv-en.sv?\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#A.1.3 - Verify that the line counts are the same for the two languages.\n",
    "print(\"The line counts are the same for both europarl-v7.sv-en.en and europarl-v7.sv-en.sv?\\n\" + str(lineCount_en_1 == lineCount_sv_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "naval-attraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.2.1 - Preprocess the text from both RDDs by lowercase-ing and tokenize-ing (split on space) the text:\n",
    "en_2 = en_1.map(func_lowercase_split)\n",
    "sv_2 = sv_1.map(func_lowercase_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "significant-ordering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line counts are the same for europarl-v7.sv-en.en before and after processing?\n",
      "True\n",
      "The line counts are the same for europarl-v7.sv-en.sv before and after processing?\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#A.2.3 Verify that the line counts still match after the pre-processing.\n",
    "print(\"The line counts are the same for europarl-v7.sv-en.en before and after processing?\\n\" + str(lineCount_en_1 == en_2.count()))\n",
    "print(\"The line counts are the same for europarl-v7.sv-en.sv before and after processing?\\n\" + str(lineCount_sv_1 == sv_2.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "arranged-modern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 3498375), ('of', 1659758), ('to', 1539760), ('and', 1288401), ('in', 1085993), ('that', 797516), ('a', 773522), ('is', 758050), ('for', 534242), ('we', 522849)]\n",
      "[('att', 1706293), ('och', 1344830), ('i', 1050774), ('det', 924866), ('som', 913276), ('för', 908680), ('av', 738068), ('är', 694381), ('en', 620310), ('vi', 539797)]\n"
     ]
    }
   ],
   "source": [
    "#A.3.1 - Use Spark to compute the 10 most frequently according words in the English and Swedish language corpus.\n",
    "print(en_2.flatMap(lambda x: x).map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y).takeOrdered(10, key = lambda x: -x[1]))\n",
    "print(sv_2.flatMap(lambda x: x).map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y).takeOrdered(10, key = lambda x: -x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "qualified-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.4.1 - Use this parallel corpus to mine some translations in the form of word pairs, for the two languages.\n",
    "en_3 = en_2.zipWithIndex().map(lambda x: (x[1],x[0]))\n",
    "sv_3 = sv_2.zipWithIndex().map(lambda x: (x[1],x[0]))\n",
    "en_sv = en_3.join(sv_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "driving-writing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(707940, (['\\xa0\\xa0', '.'], ['\\xa0\\xa0', '.'])), (24055, (['so', 'why', 'change', 'it?'], ['varför', 'ändra', 'på', 'den?'])), (140210, (['we', 'should', 'examine', 'these', 'aspects', 'further.'], ['vi', 'måste', 'undersöka', 'det', 'hela', 'noggrannare.'])), (462540, (['these', 'are', 'technical', 'rather', 'than', 'substantive', 'amendments.'], ['dessa', 'ändringsförslag', 'avser', 'snarare', 'formen', 'än', 'innehållet.'])), (284555, ([''], ['.']))]\n"
     ]
    }
   ],
   "source": [
    "en_sv = en_sv.filter(lambda x: (not x[1][0] is None) and (not x[1][1] is None))\n",
    "en_sv = en_sv.filter(lambda x: (len(x[1][0]) != 0) and (len(x[1][1]) != 0))\n",
    "en_sv = en_sv.filter(lambda x: ((len(x[1][0]) <= 8) and (len(x[1][1]) <= 8)))\n",
    "en_sv = en_sv.filter(lambda x: (len(x[1][0]) == len(x[1][1])))\n",
    "print(en_sv.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sv_test = en_sv.map(lambda x: x[1])\n",
    "en_sv_test.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "czech-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# release the cores for another application!\n",
    "#spark_context.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
